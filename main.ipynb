{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalplus.data import get_human_eval_plus, write_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = []\n",
    "for task_id, problem in get_human_eval_plus().items():\n",
    "    # print(f\"Task {task_id}:\")\n",
    "    # print(f\"{problem['prompt']}\")\n",
    "    # print(f\"{problem}\")\n",
    "    # print(f\"{problem['base_input'][0]}\")\n",
    "    problems.append(problem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The candidate implementation is equivalent to the canonical solution.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import inspect\n",
    "import json\n",
    "from typing import Any, Callable, Dict, List, Union\n",
    "from hypothesis import given, strategies as st, assume\n",
    "from hypothesis import Verbosity\n",
    "\n",
    "\n",
    "def extract_function(code: str, func_name: str) -> Callable:\n",
    "    \"\"\"Extract a function from a code string.\"\"\"\n",
    "    module = ast.parse(code)\n",
    "    function_def = next(node for node in module.body if isinstance(node, ast.FunctionDef) and node.name == func_name)\n",
    "    \n",
    "    locals_dict = {}\n",
    "    exec(compile(ast.Module(body=[function_def], type_ignores=[]), filename=\"<ast>\", mode=\"exec\"), globals(), locals_dict)\n",
    "    return locals_dict[func_name]\n",
    "\n",
    "def infer_type_strategy(value: Any) -> st.SearchStrategy:\n",
    "    \"\"\"Infer a Hypothesis strategy based on the type of the given value.\"\"\"\n",
    "    if isinstance(value, bool):\n",
    "        return st.booleans()\n",
    "    elif isinstance(value, int):\n",
    "        return st.integers(min_value=value-100, max_value=value+100)\n",
    "    elif isinstance(value, float):\n",
    "        return st.floats(min_value=value-100, max_value=value+100, allow_nan=False, allow_infinity=False)\n",
    "    elif isinstance(value, str):\n",
    "        return st.text(min_size=len(value), max_size=len(value)+10)\n",
    "    elif isinstance(value, list):\n",
    "        if not value:\n",
    "            return st.lists(st.integers(), min_size=0, max_size=10)\n",
    "        element_strategy = infer_type_strategy(value[0])\n",
    "        return st.lists(element_strategy, min_size=len(value), max_size=len(value)+5)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported type: {type(value)}\")\n",
    "\n",
    "def generate_hypothesis_test(task: Dict[str, Any]) -> Callable:\n",
    "    \"\"\"Generate a Hypothesis test function based on the task's base_input.\"\"\"\n",
    "    arg_strategies = [infer_type_strategy(arg) for arg in task[\"base_input\"][0]]\n",
    "    \n",
    "    @settings(max_examples=10000, deadline=None, derandomize=True)\n",
    "    @given(st.tuples(*arg_strategies))\n",
    "    def test_equivalence(canonical_func: Callable, candidate_func: Callable, args: tuple):\n",
    "        try:\n",
    "            canonical_result = canonical_func(*args)\n",
    "            candidate_result = candidate_func(*args)\n",
    "            \n",
    "            if isinstance(canonical_result, float) and isinstance(candidate_result, float):\n",
    "                assert abs(canonical_result - candidate_result) <= task[\"atol\"]\n",
    "            else:\n",
    "                assert canonical_result == candidate_result\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred with inputs: {args}\")\n",
    "            raise e\n",
    "    \n",
    "    return test_equivalence\n",
    "\n",
    "def test_implementation(task: Dict, candidate_implementation: str) -> bool:\n",
    "    \"\"\"Test if the candidate implementation is equivalent to the canonical solution using Hypothesis.\"\"\"\n",
    "    \n",
    "    canonical_func = extract_function(task[\"prompt\"] + task[\"canonical_solution\"], task[\"entry_point\"])\n",
    "    candidate_func = extract_function(task[\"prompt\"] + candidate_implementation, task[\"entry_point\"])\n",
    "    \n",
    "    try:\n",
    "        hypothesis_test = generate_hypothesis_test(task)\n",
    "        hypothesis_test(canonical_func, candidate_func)\n",
    "        return True\n",
    "    except AssertionError:\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "task_json = '''\n",
    "{\n",
    "    \"task_id\": \"HumanEval/0\",\n",
    "    \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\",\n",
    "    \"canonical_solution\": \"\\n    sorted_numbers = sorted(numbers)\\n    for i in range(len(sorted_numbers) - 1):\\n        if sorted_numbers[i + 1] - sorted_numbers[i] < threshold:\\n            return True\\n    return False\\n\",\n",
    "    \"entry_point\": \"has_close_elements\",\n",
    "    \"atol\": 0,\n",
    "    \"base_input\": [\n",
    "        [[1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3],\n",
    "        [[1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05],\n",
    "        [[1.0, 2.0, 5.9, 4.0, 5.0], 0.95],\n",
    "        [[1.0, 2.0, 5.9, 4.0, 5.0], 0.8],\n",
    "        [[1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1]\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "candidate_implementation = \"\"\"\n",
    "    for i in range(len(numbers)):\n",
    "        for j in range(i + 1, len(numbers)):\n",
    "            if abs(numbers[i] - numbers[j]) < threshold:\n",
    "                return True\n",
    "    return False\n",
    "\"\"\"\n",
    "\n",
    "is_equivalent = test_implementation(problems[0], candidate_implementation)\n",
    "print(f\"The candidate implementation is {'equivalent' if is_equivalent else 'not equivalent'} to the canonical solution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
